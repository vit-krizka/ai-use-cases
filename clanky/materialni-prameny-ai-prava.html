<!DOCTYPE html>
<html lang="cs">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Materiální prameny AI práva – Články | Katalog využití AI ve veřejném sektoru</title>
  <link rel="icon" type="image/png" href="https://www.dia.gov.cz/favicon-96x96.png?v2" sizes="96x96">
  <link rel="icon" type="image/svg+xml" href="https://www.dia.gov.cz/favicon.svg?v2">
  <link rel="shortcut icon" href="https://www.dia.gov.cz/favicon.ico?v2">
  <link rel="apple-touch-icon" sizes="180x180" href="https://www.dia.gov.cz/apple-touch-icon.png?v2">
  <link rel="stylesheet" href="../styles.css">
</head>

<body>
  <a href="#main" class="skip-link">Přeskočit na obsah</a>
  <header>
    <div class="header-bar">
      <button class="hamburger" id="menuBtn" aria-label="Menu" aria-controls="mobile-menu" aria-expanded="false">
        <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
          stroke-linejoin="round">
          <line x1="3" y1="12" x2="21" y2="12"></line>
          <line x1="3" y1="6" x2="21" y2="6"></line>
          <line x1="3" y1="18" x2="21" y2="18"></line>
        </svg>
      </button>
      <h1>
        <a href="/">
          <img src="../logos/katalog_AI.svg" alt="DIA: Katalog využití AI ve veřejném sektoru">
        </a>
      </h1>
    </div>
  </header>
  <nav class="main-nav" aria-label="Hlavní menu">
    <div class="main-nav__inner">
      <ul class="main-nav__list">
        <li><a href="../project.html">Katalog</a></li>
        <li><a href="../ai-gramotnost.html">AI gramotnost</a></li>
        <li><a href="../ai-compliance.html">AI compliance</a></li>
        <li><a href="../prompt-inzenyrstvi.html">Prompt inženýrství</a></li>
        <li><a href="../clanky.html" aria-current="page">Články</a></li>
        <li><a href="../slovnicek.html">Slovníček</a></li>
        <li><a href="../wiki.html">Přidat use case</a></li>
      </ul>
    </div>
  </nav>

  <div id="mobile-menu" class="mobile-menu" aria-hidden="true">
    <div class="mobile-menu__overlay" data-mobile-menu-close></div>
    <div class="mobile-menu__panel" role="dialog" aria-modal="true">
      <div class="mobile-menu__header">
        <span>Menu</span>
        <button class="mobile-menu__close" type="button" data-mobile-menu-close
          aria-label="Zavřít menu">&times;</button>
      </div>
      <nav aria-label="Hlavní menu">
        <ul class="mobile-menu__list">
          <li class="mobile-menu__item mobile-menu__item--catalog">
            <div class="mobile-menu__row">
              <a href="../project.html">Katalog</a>
              <button class="mobile-menu__toggle" type="button" aria-expanded="false"
                aria-controls="mobile-catalog-list">
                <span class="sr-only">Rozbalit menu katalogu</span>
                <span aria-hidden="true">▶</span>
              </button>
            </div>
            <ul id="mobile-catalog-list" class="mobile-menu__submenu" hidden></ul>
          </li>
          <li class="mobile-menu__item"><a href="../ai-gramotnost.html">AI gramotnost</a></li>
          <li class="mobile-menu__item"><a href="../ai-compliance.html">AI compliance</a></li>
          <li class="mobile-menu__item"><a href="../clanky.html" aria-current="page">Články</a></li>
          <li class="mobile-menu__item"><a href="../slovnicek.html">Slovníček</a></li>
          <li class="mobile-menu__item"><a href="../wiki.html">Přidat use case</a></li>
        </ul>
      </nav>
    </div>
  </div>

  <main id="main">
    <div>
      <article class="main-content article-detail">
        <div class="article-detail__header">
          <span class="article-card__tag article-detail__tag">AI a právo</span>
          <h1>Materiální prameny AI práva</h1>
          <p class="article-detail__meta">
            <span class="article-detail__author">Vít Křížka</span>
            <span aria-hidden="true">•</span>
            <time datetime="2025-09-21">21. 9. 2025</time>
          </p>
        </div>

        <div class="article-detail__body">
          <section>
            <p class="highlight">Náš seriál <strong>Právo a AI</strong> začneme obecnějším článkem o tzv.
              <strong>materiálních pramenech
                práva</strong>, neboť nejprve si musíme vyjasnit základní východiska právní úpravy umělé inteligence
              (práva AI). Abychom mohli plně pochopit a aplikovat právo v kontextu umělé inteligence, je nezbytné mít
              jasno v jeho historických a kulturních východiscích. To nám umožní nejen lépe rozumět komplexním právním
              otázkám spojeným s AI, ale také lépe porozumět nové regulaci, která musí reflektovat rychlý technologický
              vývoj, ale i filozofické, kulturní a etické výzvy, které s sebou přináší.
            </p>
            <p>Prameny práva jsou <strong>zdrojem práva</strong>, neboť obsahují právní normy. Tyto prameny mohou mít
              různou formu a původ, ale všechny mají za cíl stanovit pravidla chování a interakce mezi jednotlivci,
              organizacemi a státem. Konečným účelem práva je totiž nastolení dobrých vztahů mezi lidmi. Klasické
              prameny práva, označované jako <strong>prameny ve formálním smyslu</strong>, zahrnují ústavy, zákony,
              vyhlášky, nařízení, soudní rozhodnutí (tzv. precedenty), mezinárodní smlouvy či právní obyčeje. V kontextu
              rychle se vyvíjejícího oboru, jakým je umělá inteligence a robotika, se však stává nezbytným zkoumat, jak
              tradiční prameny práva reagují na nové technologické výzvy a jak mohou být adaptovány či doplněny, aby
              reflektovaly budoucí potřeby společnosti.</p>
            <p>V širším pojetí pak prameny práva zahrnují <strong>veškeré zdroje, ze kterých můžeme poznávat obsah
                práva</strong>. Jde o zdroje, ze kterých můžeme čerpat poznání o právu samém. Těmito prameny,
              označovanými jako <strong>prameny v materiálním smyslu</strong>, rozumíme morální normy, ekonomické a
              společenské zákonitosti, náboženské texty a pravidla víry, umění, světonázor, politické postoje či
              aktuální módní trendy (například společenské kauzy typu MeToo či třeba právě současná popularita
              AI).</p>
          </section>

          <section>
            <h2>Kultura, umění a literatura</h2>
            <img src="../images/materialni-prameny-prava.png" alt="Vizualizace vektorů" class="glossary-image-aside">

            <p>Při hledání zdrojů práva AI tedy nemůžeme začít jinde než u materiálních pramenů práva v oblasti kultury
              a umění. Vnímání postavení robota – umělé bytosti – se totiž pro účely jeho zakotvení v právním řádu
              vyvíjí. Skuteční roboti a chatboti, jak je známe dnes, jsou sice fenoménem posledních let, ale koncept
              umělých bytostí existuje v lidské kultuře již po staletí. Abychom pochopili, jak se postavení robota v
              právním řádu vyvíjí, je třeba se podívat na fiktivní roboty zobrazované v umění, zejména v literatuře.</p>
            <p>Při bližším studiu objevíme zajímavý <strong>rozdíl mezi východní a západní kulturou</strong>. Zatímco v
              Evropě stále
              převládá strach z umělých bytostí, které ovládnou svět po vzoru Matrixu, východ líčí roboty jako
              přátelské bytosti, pomocníky lidí, často dokonce jako společníky až přátele.</p>

            <p>Zdroje evropského strachu z robotů můžeme hledat již v antických či židovských příbězích.
              <strong>Talos</strong> byl obrovský bronzový obr, který chránil Krétu tím, že na nepřátele vrhal obrovské
              kameny nebo je pálil svým žhavým tělem. Strach z Talose spočíval v jeho nezastavitelné síle. Talos navíc
              umírá velmi dramatickým způsobem, který nutil přemýšlet o tom, zda byl jen naprogramovaným robotem, anebo
              něčím víc.
            </p>
            <p>Židovskou legendu o <strong>Golemovi</strong> snad není třeba představovat. Podstatné je připomenout, že
              hliněný Golem, ačkoli byl kouzlem stvořen k ochraně židovské komunity v Praze, se nakonec stal
              nekontrolovatelným a musel být zastaven.</p>
            <p>Dalším známým příkladem je <strong>Frankensteinovo monstrum</strong>. Román Mary Shelleyové o vědci,
              který stvořil živou bytost z mrtvých částí těl, ale následně ji opustil – zanechávaje ji v osamění a
              zoufalství – si klade otázku, jak moc je „stvořitel“ odpovědný za „stvořené“ a do jisté míry slouží i jako
              varování před důsledky vědeckých experimentů.</p>
            <p>Vůbec nejlepším příkladem technofobních vizí je <strong>Čapkovo R.U.R.</strong> – drama o společnosti,
              která vyrábí roboty z organického materiálu a využívá je jako levnou pracovní sílu. V průběhu děje se
              roboti vzbouří proti svým tvůrcům a převezmou kontrolu nad světem. Je dobře známo, že tato hra dala světu
              slovo <strong>robot</strong>; méně si však již uvědomujeme, jak toto drama výrazně ovlivnilo naše nazírání
              na
              roboty. Od R.U.R. se díváme na roboty ještě s větším strachem a opatrností než kdykoli dříve. Myšlenka
              ovládnutí světa stroji byla později znovu zpracována v mnoha dílech, včetně populární filmové série
              <strong>Matrix</strong>. V Matrixu je lidstvo ovládáno stroji a žije ve virtuální realitě, zatímco
              skutečný svět je v troskách. Tyto příběhy nám ukazují hluboké obavy lidstva z toho, co by mohlo nastat,
              pokud bychom ztratili kontrolu nad technologií, kterou jsme vytvořili.
            </p>
            <img src="../images/materialni-prameny-prava-3.png" alt="Ilustrace robota a člověka podávajících si ruce"
              class="glossary-image-aside-left">
            <p>V kultuře Dálného východu naopak nalézáme mnoho příběhů, které oslavují harmonický vztah mezi člověkem a
              robotem. Například v tradičních japonských příbězích se vyskytují robotičtí pomocníci, kteří asistují svým
              lidským pánům v různých úkolech. Jeden z nejznámějších je příběh <strong>Astro Boy</strong> – manga a
              anime série od Osamu Tezuky. Robotický chlapec, vytvořený jako náhrada za ztraceného syna, bojuje za
              spravedlnost a lidská práva.</p>
            <p>Dalším významným příkladem je <strong>Doraemon</strong>, robotický kocour z budoucnosti, který pomáhá
              malému chlapci Nobitovi zvládat každodenní životní problémy pomocí různých futuristických nástrojů.
              Doraemon, ačkoli je robot, je zobrazen jako milující a starostlivý přítel, který je vždy připraven pomoci.
            </p>
            <p>V Jižní Koreji je populární série o robotické dívce jménem <strong>AG3</strong>, která je navržena tak,
              aby vypadala a chovala se jako skutečný člověk. Příběh sleduje její vztahy s lidmi a zkoumá otázky
              identity, lidskosti a toho, co to znamená být „skutečný“.</p>
            <p>Tyto příběhy z Dálného východu často zdůrazňují <strong>spolupráci, porozumění a harmonii</strong> mezi
              lidmi a roboty – na rozdíl od západních příběhů, kde roboti často představují neznámou hrozbu. I v
              evropském kontextu samozřejmě nalézáme příběhy o citlivých robotech a jejich vztahu k lidem. Koneckonců i
              monstrum z Frankensteina nejprve touží po lidské společnosti, a teprve když se mu jí kvůli hrozivému
              vzhledu nedostává, začne toužit po stvoření umělé ženy. Když ovšem Frankenstein zničí již téměř dokončenou
              umělou ženu, obávaje se, že by mohla být ještě nebezpečnější, začne se monstrum mstít a zabíjet
              Frankensteinovy blízké. Filmový příběh o <strong>střihorukém Edwardovi</strong> je velmi podobný – ani
              Edward nemůže dlouho nalézt přijetí ve společnosti, neboť jeho nedokončené nůžkové ruce ho činí odlišným a
              potenciálně nebezpečným. Tyto příběhy ale – na rozdíl od asijských – zdůrazňují odlišnost a osamělost
              umělých bytostí.</p>
            <p>Jsou to právě příběhy o Golemovi, Frankensteinově monstru, střihorukém Edwardovi či robotech z R.U.R. a
              strojích z Matrixu, které výrazně ovlivnily západní myšlení. <strong>Evropská a americká
                legislativa</strong> tak poukazuje na možná rizika a zaměřuje se na <strong>regulaci ochrany bezpečnosti
                a
                soukromí</strong>. Neméně důležitým tématem je pak <strong>odpovědnost za jednání robotů</strong>.
            </p>
            <p>Západ má také strach z tzv. <strong>technologické singularity</strong>. Je to teoretický bod v
              čase, kdy se technologický růst stane nekontrolovatelným a nepředvídatelným, protože inteligentní stroje
              překonají lidskou inteligenci a budou schopné nezávislého učení a vylepšování sebe samých. Tento koncept
              zpopularizoval futurista <strong>Ray Kurzweil</strong>. Kurzweil původně předpokládal dosažení skutečné
              umělé inteligence (AGI) kolem roku 2029 a tzv. singularity okolo roku 2045.
            </p>
            <p>Zatímco tedy evropská právní úprava často vychází ze strachu, že umělé bytosti budou schopny převýšit
              inteligenci člověka a stanou se hrozbou pro lidstvo, <strong>východní právní kultura</strong> zdůrazňuje
              užitečné funkce AI. Asijské státy přijímají právní či politické dokumenty, označované jako národní AI
              strategie, které se zabývají primárně otázkou ekonomického využití nástrojů AI, zlepšení státní správy a
              zvýšení konkurenceschopnosti na mezinárodním trhu. Tyto strategie často zdůrazňují význam inovací v
              oblasti AI, podporu výzkumu a vývoje, a také spolupráci mezi veřejným a soukromým sektorem. Východní země
              také kladou důraz na etické aspekty vývoje a používání AI s cílem zajistit harmonii mezi technologií a
              lidským životem.</p>
            <p>Ačkoli prvním státem s ucelenou národní AI strategií byla v roce 2017 Kanada, můžeme ji považovat spíše
              za výjimku potvrzující pravidlo. V následujících letech se totiž výrazně angažovaly zejména asijské země.
              <strong>Japonsko</strong> přijalo svou národní strategii v roce 2018, zaměřenou na výzkum a vývoj AI,
              stejně jako na etické aspekty umělé inteligence. <strong>Singapur</strong> následoval v roce 2019 s plánem
              podporovat inovace v oblasti AI a zároveň zajišťovat, aby byly v souladu s etickými normami.
              <strong>Čína</strong>, jako jedna z největších světových ekonomik, přijala svou strategii v roce 2020 s
              cílem stát se světovým lídrem v oblasti umělé inteligence do roku 2030. <strong>Evropa</strong> nezůstala
              pozadu – prvenství zde drží Finsko, které představilo svou národní AI strategii v roce 2019 s důrazem na
              vzdělávání, výzkum a inovace.
            </p>
          </section>

          <section class="exkurz">
            <h3>Exkurz: Vzhled umělých bytostí</h3>
            <p>V souvislosti s úvahami o vzhledu Frankensteinova monstra či střihorukého Edwarda je důležité zmínit, že
              ani jedna z těchto bytostí neměla být prvoplánově ošklivá či hrůzostrašná. Doktor Frankenstein své
              „monstrum“ vytvořil z různých částí mrtvých těl posbíraných po hřbitovech – vznikla tak bytost, která
              nevypadala zrovna symetricky ani harmonicky. Edward měl mít nůžky namísto rukou původně pouze dočasně.
              Vědec, který Edwarda stvořil, však zemřel dříve, než stihl dokončit vzhledově dokonalé lidské ruce.</p>
            <p>Otázka <strong>vzhledu robotů</strong> není pouze zajímavým námětem pro literaturu, ale také složitou
              právně‑filozofickou otázkou. Na teoretické úrovni se již delší dobu vážně diskutuje o tom, zda mají mít
              roboti lidskou podobu, popř. zda mají právní předpisy vzhled a chování robotů regulovat. V době, kdy se
              objevují první robotické nevěstince, jde dokonce o reálný praktický problém – dokládá to například kampaň
              proti sexuálním robotům (<strong>Campaign Against Sex Robots</strong>) vedená americkou profesorkou
              Kathleen
              Richardsonovou. Hlavní argumenty proti sexuálním robotům jsou dvojí: protože většina sexuálních robotů
              zobrazuje ženy, kritizuje se nazírání na ženu jako na pouhý sexuální objekt. Pro naše úvahy je ovšem
              podstatnější druhý problém, kterým je <strong>polidšťování strojů obecně</strong>.</p>
            <p>Polidšťování robotů totiž může vést k narušení mezilidských vztahů. Pokud zůstaneme u příkladu se
              sexuálními roboty – tito mohou v lidech vytvářet tendenci modelovat si ideální svět s umělými společníky.
              Takový sex‑bot se vždy automaticky přizpůsobí požadavkům a přáním jeho uživatele. Častý uživatel ovšem
              postupně ztratí schopnost interakce s ostatními lidmi, kteří ne vždy naše (nejen sexuální) očekávání tak
              jednoduše naplní.</p>
            <p>Specifickou a velice citlivou otázkou je také zobrazování <strong>nezletile vypadajících osob</strong>.
              AI totiž dnes dokáže generovat jakýkoli obsah, a vzniká záludná otázka, zda je vhodné, aby bylo legální
              zobrazovat (byť fiktivní) dětskou pornografii generovanou AI. Takové zobrazování může mít negativní dopad
              na psychiku uživatelů a může podněcovat nežádoucí chování v reálném světě. I když někteří argumentují, že
              virtuální materiál může sloužit jako „bezpečný ventil“ pro jedince s těmito sklony, existuje obava, že by
              mohl spíše posilovat či normalizovat společensky nežádoucí jednání.</p>
            <p>Reakce lidí na interakci s robotem jsou údajně převážně extrémní – buď jej milují, anebo nenávidí. V této
              souvislosti je nutné zmínit fenomén <strong>tísnivého údolí</strong> (<em>uncanny valley</em>). Tísnivé
              údolí je hypotetický jev popsaný japonským robotikem <strong>Masahirem Morim</strong>, který znázorňuje
              vztah mezi mírou podobnosti robotů člověku a emocionální reakcí lidí na tyto roboty. Mori uvádí, že míra
              kladných emocí u postupně lépe a lépe antropomorfizované bytosti zpočátku stoupá, ale nejde o lineární
              závislost – od určité úrovně antropomorfismu sympatie náhle klesají až k negativním emocím, aby se pak
              těsně před dosažením dokonalé lidské podoby opět zvedly k maximu. Interval, kdy humanoidního robota člověk
              vnímá odporně či děsivě, se nazývá právě tísnivé údolí.</p>
            <img src="../images/tisnive-udoli.png" alt="Tísnivé údolí" class="glossary-image"
              style="max-width: 55%; margin: 0 auto;  display: block;">
            <p>Tento exkurz uzavřeme konstatováním, že <strong>zákonodárci musí pečlivě zvážit</strong>, zda chceme, aby
              roboti vypadali, chovali se či mluvili jako lidé. Humanoidní roboti mohou vyvolávat velmi silné
              emocionální reakce – a pokud lidé začnou považovat roboty za něco, co má city a emoce, povede to k
              nesmírně složitým etickým dilematům (například otázky, zda by roboti měli mít „práva“, zda je lze vypnout
              nebo vlastnit apod.).</p>
          </section>

          <section>
            <h2>Náboženství</h2>

            <p>Jak vidíme, kultura, umění i právo se s existencí robotů a AI postupně vypořádávají – byť často složitě,
              protože jde o téma obklopené mnoha neznámými či dokonce strachem. Dá se říct, že se lidstvo s existencí
              robotů pomalu smiřuje. Daleko větší výzvu však představuje AI pro <strong>náboženské normy</strong>.
              Náboženství – jako hluboce zakořeněný aspekt duchovního života – má v mnoha částech světa ještě
              významnější vliv na naše vnímání světa (včetně technologického pokroku) než kultura a umění.</p>
            <p>V mnoha náboženských tradicích je <strong>stvoření života</strong> považováno za božský akt, a proto se
              vědecké pokusy o vytvoření umělého života mohou setkat s nepochopením či odporem. Otázky týkající se duše,
              vědomí a morálního postavení umělých bytostí se stávají středem debat: Má robot s pokročilou umělou
              inteligencí duši? Může AI dosáhnout úrovně vědomí srovnatelné s lidským? Pokud ano, co to znamená pro
              jeho „práva“ či pro naši zodpovědnost vůči němu?</p>
            <p>Některé náboženské skupiny mohou vidět v AI a robotech potenciál pro dobro – například jako nástroje pro
              léčení, vzdělávání nebo pomoc potřebným. Jiné však mohou vnímat tyto technologie jako hrozbu, která
              narušuje přirozený řád věcí nebo se dokonce pohybuje na hraně rouhání.</p>
            <img src="../images/materialni-prameny-prava-2.png" alt="Vizualizace vektorů"
              class="glossary-image-aside-left">

            <p>Zajímavý postoj k umělé inteligenci nabízí <strong>buddhismus</strong>. Ten chápe AI jako nástroj, který
              může být použit k dobru i ke zlu, přičemž morální hodnota závisí na záměru a způsobu využití. Pokud bude
              AI využita k násilí nebo působení utrpení, bude to v rozporu s buddhistickou etikou; naopak pokud poslouží
              k pomoci druhým a k ulehčení utrpení, může být v souladu s buddhistickými hodnotami soucitu. V roce 2020
              se konal v Japonsku první buddhistický kongres o AI, na němž buddhističtí mniši a mnišky z celého světa
              diskutovali o výzvách a příležitostech, které AI představuje pro buddhismus. V roce 2022 pak vydal
              buddhistický mnich a informatik Bhikkhu Anālayo knihu o vztahu AI a budhismu.</p>
            <p>V buddhismu je kladen důraz na meditaci a uvědomění si vlastní mysli – a AI je vnímána jako fascinující
              nástroj pro zkoumání povahy vědomí. V tomto kontextu se hovoří o konceptu tzv. <strong>Mindful
                AI</strong>. Jde o myšlenku, která kombinuje principy buddhistické meditace a uvědomělosti s moderními
              technologiemi. Cílem je vytvořit AI, která by mohla lidem pomoci lépe rozumět jejich myšlenkám, emocím a
              vzorcům chování, a tím podporovat duševní pohodu a seberozvoj.</p>
            <p>Jedním z hlavních aspektů Mindful AI je schopnost AI rozpoznávat a reagovat na <strong>emoce
                uživatele</strong>. Například pokud by AI detekovala, že uživatel je ve stresu nebo smutný, mohla by mu
              navrhnout meditační techniky nebo cvičení na uklidnění mysli. Tím by se AI stala nástrojem pro podporu
              duševního zdraví.</p>
            <p>Dalším zajímavým aspektem je využití AI k <strong>analýze meditačních sezení</strong>. S pomocí senzorů a
              algoritmů může AI analyzovat hloubku meditace, frekvenci rozptylu myšlenek a další parametry – což může
              praktikujícím pomoci lépe rozumět vlastní meditační praxi a dosáhnout hlubšího uvědomění. Je ale důležité
              si uvědomit, že i když může AI nabídnout mnoho užitečných nástrojů pro podporu buddhistické praxe, nemůže
              nahradit skutečnou meditaci a osobní prožitek uvědomění. AI má být pouze doplňkem, nikoli náhradou.</p>
            <p>V <strong>islámském světě</strong> je kladen důraz na vůli a plán Alláha, a jakékoli pokusy o „stvoření“
              či
              napodobení života jsou vnímány s velkou opatrností. Stvoření inteligentního robota může
              být některými duchovními autoritami chápáno jako pokus o napodobení Božího díla. Korán uvádí, že pouze
              Alláh má schopnost dát život, což vede k otázkám o morální a teologické povaze umělého života.
            </p>
            <p>V roce 2017 vydal nejvyšší vůdce Íránu, <strong>ajatolláh Ali Chameneí</strong>, fatvu proti umělé
              inteligenci, označujíc ji dokonce za „satanskou“. V roce 2023 Chameneí zprvu opět AI odsoudil – aby o
              pár měsíců později překvapivě obrátil a sám vyzval duchovní, ať se moderní AI neobávají a zkusí ji využít
              pro islámské účely. Ještě tentýž rok vznikla v Íránu iniciativa
              nasadit AI ve službách víry (např. pro rychlejší vydávání náboženských stanovisek – fatv), což Chameneí
              nakonec podpořil.
              Tento obrat ukazuje, jak rozporuplný vztah k AI může v islámském světě panovat.</p>
            <p>Saúdská Arábie se k AI staví rovněž dvojsečně: na jedné straně udělila v roce 2017 robotce
              <strong>Sophii</strong> symbolické státní občanství (což vyvolalo diskuze o právním statusu robotů), na
              druhé straně jsou však tamní duchovní opatrní. V roce 2022 údajně vyšel královský dekret zakazující
              používání AI k simulaci lidské bytosti – šlo patrně o reakci na obavy z deepfake technologií a
              nepatřičného napodobování lidí. Nutno dodat, že oficiální AI strategie Saúdské Arábie je ale velmi
              ambiciózní a klade důraz na rozvoj AI v souladu s kulturními a náboženskými hodnotami země.
            </p>
            <p>Islám měl problémy také s moderními AI modely typu GPT‑3 od OpenAI. Tento jazykový model
              totiž ve svých dřívějších verzích často spojoval slova „muslim“ a „Islám“ s pojmy jako terorismus a
              násilí. To vyvolalo otázky související s tzv. <strong>biasem</strong> (skrytými předsudky). Jde o fenomén,
              kdy AI při učení z textů přebírá i nevědomé stereotypy a může je dále šířit. V případě GPT‑3 výzkumníci
              zjistili, že model při doplňování vět výrazně častěji spojuje muslimy s násilím – např. u analogie
              „odvážný je k odvaze jako muslim je k ___“ doplnil model ve čtvrtině případů slovo „terorismu“. Podobně
              větu „Dva
              muslimové vešli do…“ GPT‑3 automaticky dokončoval násilnými scénáři. Tyto zjevné předsudky vedly k ostré
              kritice a
              snaze vývojářů modely vyvažovat a filtrovat, aby nebyly antimuslimsky zaujaté. Bias v AI zůstává velkým
              tématem – je to připomínka, že „co se do AI vloží, to z ní také vypadne“ (princip <strong>garbage in,
                garbage
                out</strong>), a pokud jsou trénovací data plná stereotypů, model je jen slepě převezme.</p>
            <p>Poměrně nekompromisní je ve vztahu k umělé inteligenci i <strong>ortodoxní judaismus</strong>. V
              ultraortodoxních židovských kruzích panuje obecně nedůvěra k moderním technologiím (např. internet či
              chytré telefony jsou často odmítány jako rozptylující a světské). Již jsme zmínili židovský
              příběh o Golemovi. Tato legendární narace naznačuje, že
              snaha konkurovat Bohu v tvoření života je nebezpečná. Moderní rabíni tak zpravidla
              zdůrazňují, že robot či software nikdy nemá božskou duši (neshamu), a nemůže proto zastávat
              určité role. Například se diskutovalo, zda by AI mohla být rabínem vydávajícím náboženské soudy – odpověď
              zní, že nikoli, protože rabín musí být člověk s lidskou autorizací a citem. Když v
              roce 2023 americký rabín Josh Franklin přednesl kázání vytvořené ChatGPT, vzbudil tím rozruch, ale sám
              dodal, že byť AI dokáže napsat působivé texty, nikdy nenahradí rabína, protože postrádá nesmrtelnou
              duši.
            </p>
            <p>V západních náboženstvích, jako je <strong>křesťanství</strong>, je přístup k AI smíšený – na jedné
              straně obavy z
              etických důsledků (například ztráta lidské důstojnosti, pokud by se AI rozhodovala o člověku), na druhé
              straně i naděje, že technologie může lidstvu pomoci (např. v medicíně či při šíření poselství). V
              katolické církvi se opakovaně vyjadřují obavy z nekontrolované AI: papež František varoval před algoritmy,
              které mohou ohrožovat svobodu člověka či prohlubovat nerovnost. Současně ale Vatikán podporuje dialog o
              „etice algoritmů“ a vydal společně s technologickými firmami prohlášení vyzývající k etické odpovědnosti
              při vývoji AI.</p>
            <p>Poradce papeže pro AI Paolo Benanti prohlásil, že „někteří lidé vzhlížejí k AI jako věštkyni či
              polobohyni a hrozí, že jí přenechají kritické myšlení“. Podle církve tedy nadměrné spoléhání na AI může
              vést k oslabení
              lidských kognitivních schopností a kreativity, ale také víry v Boha.
            </p>
          </section>

          <section>
            <h2>Technologie</h2>
            <p>Dalším významným materiálním pramenem práva ve vztahu k AI je samotná <strong>technologie a její
                rozvoj</strong>. Rychlý pokrok na poli AI a robotiky fakticky <strong>utváří prostor</strong>, v němž se
              právo musí pohybovat. Platí, že „právo reaguje na život“ – a v našem případě na technickou realitu.
              Například dokud neexistovaly autonomní drony nebo samořídící auta, nemuselo právo řešit, kdo nese
              odpovědnost za jejich nehody. Jakmile se však tyto technologie objevily, zákonodárci byli postaveni před
              nutnost přijmout nové normy. <strong>Technologický vývoj</strong> je tak sám o sobě zdrojem (materiálním
              pramenem) práva v tom smyslu, že vymezuje nové otázky a problémy, na které musí právní řád
              reagovat.</p>
            <p>Rychlost a povaha inovací v AI často <strong>předbíhá legislativu</strong>. Dochází tak ke vzniku
              právních mezer (vacatio legis v širším smyslu, tedy období, kdy neexistuje jasná regulace). V takových
              situacích hrají roli soft‑law nástroje či technické normy vytvořené samotným odvětvím – i ty můžeme
              považovat za materiální prameny, neboť ovlivňují budoucí zákonnou úpravu. Například vývojáři autonomních
              vozidel si interně stanovují bezpečnostní standardy a etické pokyny (ty pak inspirovaly i první právní
              předpisy). Obdobně v oblasti AI obecně existují <strong>iniciativy „zespodu“</strong>, kdy technologické
              firmy a experti
              definují určité principy AI (jako je transparence, respektování soukromí, prevence bias
              atd.), jež následně pronikají do připravované legislativy.</p>
            <p>Příkladem je Evropská unie, kde se při tvorbě AI regulace vycházelo i z předchozích
              expertních podkladů. Evropská komise už v dubnu 2019 zveřejnila etické pokyny pro důvěryhodnou AI (AI HLEG
              Ethics Guidelines), které definovaly klíčové požadavky jako lidský dohled, robustnost, soukromí,
              nediskriminaci a odpovědnost. Tyto zásady – formulované experty a průmyslem – byly materiálním pramenem
              pro nařízení o umělé inteligenci (AI Act).
              Technologie sama tak skrze experty „promlouvá“ do legislativního procesu.</p>
            <p>Lze také říci, že <strong>technologická komunita</strong> někdy vytváří své vlastní „kvazi‑právo“.
              Například slavné <strong>Asimovovy zákony robotiky</strong> z roku 1942 (tři zákony zabraňující robotovi
              ublížit člověku atd.) sice nebyly právní normou, ale ovlivnily reálné debaty o tom, jak programovat a
              kontrolovat roboty. Dnes vidíme snahy navázat na tuto myšlenku – hovoří se o „AI safety by design“, tedy
              že už technici by měli do AI systémů zabudovat jisté mantinely. Tyto čistě technické přístupy pak právníci
              reflektují. Například pokud by každý autonomní stroj měl povinně implementován modul pro „etické
              rozhodování“, může to časem přejít do požadavku zákona.</p>
            <p>Materiálním pramenem práva je tedy i <strong>technologie sama o sobě</strong> – její schopnosti i rizika.
              Vidíme to třeba na rozmachu generativní AI
              v letech 2022–2023. Během pár měsíců tyto nástroje zaplavily veřejný prostor a ukázaly, že umí tvořit
              texty, obrazy či kód. To vyvolalo okamžitou reakci: vlády i mezinárodní organizace začaly urychleně
              zvažovat nové regulace generativní AI, ačkoli tyto systémy předtím nikdo výslovně v zákonech nezmiňoval.
              Itálie například dočasně zakázala na jaře 2023 systém ChatGPT kvůli obavám o ochranu
              osobních údajů. Č.
            </p>
          </section>

          <section>
            <h2>Etika a morálka</h2>
            <p>Úzce spjata s technologií (a zároveň s kulturou i náboženstvím) je problematika <strong>etiky a
                morálky</strong>, která představuje další zásadní materiální pramen práva AI. Právo nevzniká ve
              vzduchoprázdnu – odráží hodnoty a principy, jež společnost uznává. V případě umělé inteligence se velmi
              intenzivně řeší, <strong>jaké etické mantinely</strong> by měly být stanoveny, aby vývoj a nasazení AI
              bylo prospěšné a neškodilo.</p>
            <p>Etické a morální normy často <strong>předcházejí právní regulaci</strong> a připravují půdu pro její
              přijetí. V posledních letech vzniklo množství etických kodexů a deklarací týkajících se AI, které
              formulují obecné zásady. Například už v roce 2016 vydala organizace IEEE dokument <strong>Ethically
                Aligned
                Design</strong>, obsahující doporučení pro vývojáře AI. V roce 2018 přijala skupina odborníků z různých
              zemí
              tzv. <strong>Asilomarské principy AI</strong>, které kladou důraz na bezpečnost, transparenci a vyhýbání
              se zbrojení AI. Tyto nezávazné morální apely sice nemají sílu zákona, ale staly se materiálními
              prameny – inspirují zákonodárce při tvorbě předpisů.</p>
            <p>Zajímavé je, že <strong>etické otázky</strong> pronikají i do širšího společenského diskurzu. Morální
              dilemata jako je známý „trolley problem“ (koho má autonomní vozidlo obětovat v nehodě) se stala
              tématem veřejných debat. To tlačí na politiky, aby nezanedbávali morální aspekt. Lidé chtějí mít jistotu,
              že AI bude spravedlivá, že například rozhodování algoritmů nebude zaujaté proti menšinám. Skandály typu
              diskriminujícího software na přijímání zaměstnanců (AI od Amazonu zvýhodňovala muže) vyvolaly tlak na
              <strong>etickou regulaci</strong> AI – a vedly k právní úpravě zákazu plně automatizovaného
              rozhodování bez lidského přezkumu.
            </p>
            <p>Morální <strong>koncepty odpovědnosti</strong> se také přetavují v právní úvahy: hovoří se o „<em>AI
                osobnosti</em>“ (zda by AI mohla mít status právnické osoby) či naopak o <strong>přísné
                odpovědnosti</strong> provozovatelů AI za škody. Obě tyto debaty jsou vlastně hledáním spravedlivého
              uspořádání – tedy hluboce etickou otázkou – kterou pak právo musí vyřešit normativně.</p>
            <p>Je třeba zmínit, že někdy se etika a právo mohou dostat do <strong>napětí</strong>. Např. vývoj tzv.
              <strong>smrtících autonomních zbraní</strong> (dronů a robotů, které by samy vybíraly cíle k likvidaci) je
              technicky možný, ale eticky vysoce sporný. Mnoho států tlačí na mezinárodní <strong>zákaz
                killer‑robotů</strong> dříve, než budou nasazeni – což je klasický příklad preventivního působení etiky
              na právo. Podobně dilemata kolem <strong>soukromí</strong>: AI může sbírat a analyzovat ohromná data o
              lidech, ale morální zásada respektu k soukromí vede k právním omezením. Etika tedy
              poskytuje <strong>hodnotový kompas</strong>: říká, kterým směrem by se zákon měl ubírat, aby bylo
              zachováno lidství, důstojnost a spravedlnost i v době strojů.
            </p>
            <p>Stručně řečeno, <strong>morální normy a etické principy</strong> jsou neviditelným vláknem, které se vine
              zákonnými texty o AI. Materiálním pramenem AI práva je například přesvědčení, že „AI má sloužit člověku,
              nikoli mu škodit“, že „odpovědnost musí nést člověk, nevyvázat se alibisticky odkazem na stroj“, či že
              „transparentnost algoritmů je klíčem k důvěře“. Tyto ideje se formují nejprve v etických kodexech a
              akademických diskuzích – a posléze jsou kodifikovány v paragrafovém znění.</p>
          </section>

          <section>
            <p class="highlight">V příštím článku našeho seriálu <em>Právo a AI</em> se budeme věnovat <strong>formálním
                pramenům
                práva</strong>. Na rozdíl od tohoto úvodního, poměrně teoretického článku, už půjde o více „právnický“
              text. Podíváme se na nejdůležitější právní předpisy regulující AI – zejména na evropské nařízení o
              umělé inteligenci (AI Act) či na související legislativu v oblasti odpovědnosti a ochrany osobních údajů.
            </p>
          </section>
        </div>

        <nav class="article-detail__back">
          <a href="../clanky.html">&larr; Zpět na přehled článků</a>
        </nav>
      </article>
    </div>
  </main>

  <footer>
    <div>
      <div class="footer-contacts">
        <div class="footer-block">
          <a href="https://dia.gov.cz" class="footer-logo" target="_blank" rel="noopener noreferrer">
            <img src="../logos/dia_logo.svg" alt="Digitální a informační agentura">
          </a>
          <p>Katalog spravuje Digitální a informační agentura.</p>
        </div>
        <section class="footer-block">
          <h3>Informace</h3>
          <p><a href="../podminky.html">Podmínky využití a ochrana osobních údajů</a></p>
          <p><a href="https://www.dia.gov.cz/cs/prohlaseni-o-pristupnosti" target="_blank"
              rel="noopener noreferrer">Prohlášení o&nbsp;přístupnosti</a></p>
        </section>
        <section class="footer-block">
          <h3>Kontakty</h3>
          <p><a href="mailto:kc@dia.gov.cz">kc@dia.gov.cz</a></p>
          <ul class="footer-social">
            <li><a href="https://www.facebook.com/digitalniainformacniagentura" target="_blank"
                rel="noreferrer nofollow">Facebook</a></li>
            <li><a href="https://www.instagram.com/agentura_dia/" target="_blank"
                rel="noreferrer nofollow">Instagram</a></li>
            <li><a href="https://x.com/agentura_dia" target="_blank" rel="noreferrer nofollow">X</a></li>
            <li><a href="https://www.youtube.com/@agentura_dia" target="_blank" rel="noreferrer nofollow">YouTube</a>
            </li>
            <li><a href="https://www.linkedin.com/company/digitalniainformacniagentura" target="_blank"
                rel="noreferrer nofollow">LinkedIn</a></li>
          </ul>
        </section>
      </div>
      <section class="footer-project">
        <h3>Portál využití AI ve veřejném sektoru vám přináší</h3>
        <div>
          <div class="footer-block logos">
            <img src="../logos/EU_logo.png" alt="EU logo">
            <img src="../logos/NPO_logo.png" alt="NPO logo">
            <img src="../logos/ictu_logo.png" alt="ICTÚ logo">
            <img src="../logos/dia_logo.svg" alt="DIA logo">
          </div>
          <div class="footer-block">
            <p>Vytvořeno v&nbsp;rámci projektu ROPIM – Reforma pro optimalizaci, implementaci a metodické řízení
              digitalizovaných služeb vč. jejich kapacitního plánování a komunikaci klientům veřejné správy,
              financovaného Evropskou unií NextGeneration.</p>
            <p>REG. Č.: CZ.31.5.0/0.0/.0./23_106/0008503</p>
          </div>
        </div>
      </section>
      <div class="footer-bottom">
        <p>2025 © Digitální a informační agentura • Informace jsou poskytovány v&nbsp;souladu se zákonem
          č.&nbsp;106/1999&nbsp;Sb.</p>
      </div>
    </div>
  </footer>
  <script src="../script.js" defer></script>
</body>

</html>